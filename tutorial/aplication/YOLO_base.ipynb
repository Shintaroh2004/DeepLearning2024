{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引継ぎ資料 YOLOv8による人数カウント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は，YOLOというモデルの概要について説明したいと思います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1，YOLO(v8)とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOとは，物体検出モデルの1つであり，画像の中に存在する物体の種類だけでなく，画像内での位置を検出するモデルとなります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F2658998%2Fa008b24d-9e18-8e86-3243-ceaf13577690.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=2d423b18161e89e5929917b44ebbd9a4\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOは，物体検出モデルの中でもかなり高速なモデルであり，YOLOのバージョン8，つまり，YOLOv8は，YOLOシリーズの中でも最速のモデルとなります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F1559455%2F45927efb-70e5-f64b-5d2b-47efda49980a.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=64f4aa7059ffc6c930b5e4335e25bd8e\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の画像において，速度という項目が，一枚の画像の分析にかかる時間を示しております．CPUで，80~130msというのは魅力的です．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOは高度な物体検出モデルにも関わらず，構造自体はシンプルで，ただのCNNになります．畳み込み層によって構成されるシンプルなモデルです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，簡単にYOLOの仕組みについて説明します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.negativemind.com/wp-content/uploads/2019/02/splitInToGrid.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず，画像をいくつかのグリッドセルと呼ばれる形に切り分けます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.negativemind.com/wp-content/uploads/2019/02/combine.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，グリッドセルに分けた画像1つ1つに，B個ずつ，サイズの異なる4角形を用意します．これを，バウンディングボックスといいます．このバウンディングボックスは，大きさ・位置に加えて，信頼度という情報と呼びます．この信頼度とは，バウンディングボックスが写す領域が背景か，物体である確率を示すものとなります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それと同時に，すべてのグリッドセルに対して，CNNによる画像分類を行い，グリッドセルに写る物体を分類し，領域ごとに，どこに何があるのかをクラスタリングしています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この2つのデータを組み合わせて，どのバウンディングボックスに何が写っているかを判断することができ，最も信頼度が大きいバウンディングボックスを選べば，物体を写す領域を取得することができます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにして，YOLOはCNNによる分類を行いまくることで，どこに何が写っているかを判断します．また，今回は学習を行いませんが，学習時はバウンディングボックスの大きさも最適化されるようです．さらに，学習データ自体は，人力でバウンディングボックスを指定しないといけないので用意するのはかなり地獄です（経験者）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2，ハンズオン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOは，学習が物凄く大変なので，ある研究機関が予め学習されたモデルを用意してくれてました．今回は，これを使わせていただきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，使用するライブラリをインストールしましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.175-py3-none-any.whl (616 kB)\n",
      "     ---------------------------------------- 0.0/616.3 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/616.3 kB 660.6 kB/s eta 0:00:01\n",
      "     - ----------------------------------- 30.7/616.3 kB 660.6 kB/s eta 0:00:01\n",
      "     -- ---------------------------------- 41.0/616.3 kB 281.8 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 41.0/616.3 kB 281.8 kB/s eta 0:00:03\n",
      "     ---- -------------------------------- 71.7/616.3 kB 281.8 kB/s eta 0:00:02\n",
      "     ----- ------------------------------- 92.2/616.3 kB 309.1 kB/s eta 0:00:02\n",
      "     ----- ------------------------------- 92.2/616.3 kB 309.1 kB/s eta 0:00:02\n",
      "     ------- ---------------------------- 122.9/616.3 kB 328.4 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 153.6/616.3 kB 367.6 kB/s eta 0:00:02\n",
      "     ---------- ------------------------- 174.1/616.3 kB 389.2 kB/s eta 0:00:02\n",
      "     ----------- ------------------------ 204.8/616.3 kB 415.7 kB/s eta 0:00:01\n",
      "     ------------- ---------------------- 235.5/616.3 kB 450.6 kB/s eta 0:00:01\n",
      "     -------------- --------------------- 256.0/616.3 kB 425.2 kB/s eta 0:00:01\n",
      "     ---------------- ------------------- 286.7/616.3 kB 442.4 kB/s eta 0:00:01\n",
      "     ----------------- ------------------ 307.2/616.3 kB 442.6 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 317.4/616.3 kB 437.0 kB/s eta 0:00:01\n",
      "     ------------------- ---------------- 337.9/616.3 kB 436.9 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 368.6/616.3 kB 458.9 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 399.4/616.3 kB 470.0 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 430.1/616.3 kB 463.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 491.5/616.3 kB 505.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 542.7/616.3 kB 532.5 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 593.9/616.3 kB 566.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 616.3/616.3 kB 562.2 kB/s eta 0:00:00\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (1.23.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (5.9.4)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (2.28.1)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (4.7.0.68)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (9.3.0)\n",
      "Collecting scipy>=1.4.1\n",
      "  Downloading scipy-1.11.2-cp310-cp310-win_amd64.whl (44.0 MB)\n",
      "     ---------------------------------------- 0.0/44.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/44.0 MB 1.9 MB/s eta 0:00:23\n",
      "     ---------------------------------------- 0.1/44.0 MB 1.1 MB/s eta 0:00:41\n",
      "     ---------------------------------------- 0.2/44.0 MB 1.2 MB/s eta 0:00:38\n",
      "     --------------------------------------- 0.2/44.0 MB 980.4 kB/s eta 0:00:45\n",
      "     ---------------------------------------- 0.3/44.0 MB 1.2 MB/s eta 0:00:36\n",
      "     ---------------------------------------- 0.3/44.0 MB 1.2 MB/s eta 0:00:37\n",
      "     ---------------------------------------- 0.4/44.0 MB 1.1 MB/s eta 0:00:39\n",
      "     ---------------------------------------- 0.5/44.0 MB 1.2 MB/s eta 0:00:37\n",
      "     ---------------------------------------- 0.5/44.0 MB 1.2 MB/s eta 0:00:36\n",
      "      --------------------------------------- 0.6/44.0 MB 1.3 MB/s eta 0:00:34\n",
      "      --------------------------------------- 0.7/44.0 MB 1.3 MB/s eta 0:00:33\n",
      "      --------------------------------------- 0.8/44.0 MB 1.4 MB/s eta 0:00:32\n",
      "      --------------------------------------- 0.8/44.0 MB 1.4 MB/s eta 0:00:32\n",
      "      --------------------------------------- 0.9/44.0 MB 1.4 MB/s eta 0:00:32\n",
      "      --------------------------------------- 1.0/44.0 MB 1.4 MB/s eta 0:00:31\n",
      "     - -------------------------------------- 1.1/44.0 MB 1.5 MB/s eta 0:00:30\n",
      "     - -------------------------------------- 1.2/44.0 MB 1.5 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.3/44.0 MB 1.5 MB/s eta 0:00:28\n",
      "     - -------------------------------------- 1.4/44.0 MB 1.6 MB/s eta 0:00:27\n",
      "     - -------------------------------------- 1.5/44.0 MB 1.6 MB/s eta 0:00:27\n",
      "     - -------------------------------------- 1.6/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 1.7/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 1.8/44.0 MB 1.7 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 1.9/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 2.0/44.0 MB 1.7 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 2.1/44.0 MB 1.7 MB/s eta 0:00:25\n",
      "     - -------------------------------------- 2.1/44.0 MB 1.7 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 2.2/44.0 MB 1.7 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.2/44.0 MB 1.7 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.3/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.4/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.5/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.5/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.6/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.7/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.8/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.9/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.9/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 3.0/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 3.1/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 3.2/44.0 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 3.2/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.3/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.4/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.4/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.5/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.6/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.7/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.8/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.9/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 3.9/44.0 MB 1.7 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 4.0/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 4.1/44.0 MB 1.7 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 4.2/44.0 MB 1.7 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 4.3/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 4.3/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     --- ------------------------------------ 4.4/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 4.5/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 4.6/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 4.6/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 4.7/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 4.8/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 4.9/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ---- ----------------------------------- 5.0/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ---- ----------------------------------- 5.0/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ---- ----------------------------------- 5.1/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ---- ----------------------------------- 5.1/44.0 MB 1.6 MB/s eta 0:00:25\n",
      "     ---- ----------------------------------- 5.2/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ---- ----------------------------------- 5.3/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ---- ----------------------------------- 5.4/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ---- ----------------------------------- 5.5/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ----- ---------------------------------- 5.6/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ----- ---------------------------------- 5.7/44.0 MB 1.7 MB/s eta 0:00:24\n",
      "     ----- ---------------------------------- 5.8/44.0 MB 1.7 MB/s eta 0:00:24\n",
      "     ----- ---------------------------------- 5.9/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ----- ---------------------------------- 6.0/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ----- ---------------------------------- 6.1/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ----- ---------------------------------- 6.1/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ----- ---------------------------------- 6.1/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ----- ---------------------------------- 6.2/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ----- ---------------------------------- 6.3/44.0 MB 1.6 MB/s eta 0:00:24\n",
      "     ----- ---------------------------------- 6.3/44.0 MB 1.6 MB/s eta 0:00:23\n",
      "     ----- ---------------------------------- 6.5/44.0 MB 1.6 MB/s eta 0:00:23\n",
      "     ----- ---------------------------------- 6.6/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ------ --------------------------------- 6.7/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ------ --------------------------------- 6.8/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ------ --------------------------------- 6.9/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ------ --------------------------------- 6.9/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ------ --------------------------------- 7.1/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ------ --------------------------------- 7.1/44.0 MB 1.7 MB/s eta 0:00:23\n",
      "     ------ --------------------------------- 7.2/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 7.3/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 7.4/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 7.6/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 7.7/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 7.8/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 7.9/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 7.9/44.0 MB 1.7 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 8.1/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.2/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.2/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.3/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.5/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.5/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.5/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.6/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 8.7/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 8.8/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 9.0/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 9.1/44.0 MB 1.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 9.2/44.0 MB 1.7 MB/s eta 0:00:20\n",
      "     -------- ------------------------------- 9.3/44.0 MB 1.7 MB/s eta 0:00:20\n",
      "     -------- ------------------------------- 9.5/44.0 MB 1.8 MB/s eta 0:00:20\n",
      "     -------- ------------------------------- 9.6/44.0 MB 1.8 MB/s eta 0:00:20\n",
      "     -------- ------------------------------- 9.7/44.0 MB 1.8 MB/s eta 0:00:20\n",
      "     -------- ------------------------------- 9.8/44.0 MB 1.8 MB/s eta 0:00:20\n",
      "     -------- ------------------------------- 9.9/44.0 MB 1.8 MB/s eta 0:00:20\n",
      "     --------- ------------------------------ 10.1/44.0 MB 1.8 MB/s eta 0:00:20\n",
      "     --------- ------------------------------ 10.2/44.0 MB 1.8 MB/s eta 0:00:20\n",
      "     --------- ------------------------------ 10.3/44.0 MB 1.8 MB/s eta 0:00:19\n",
      "     --------- ------------------------------ 10.4/44.0 MB 1.8 MB/s eta 0:00:19\n",
      "     --------- ------------------------------ 10.5/44.0 MB 1.8 MB/s eta 0:00:19\n",
      "     --------- ------------------------------ 10.6/44.0 MB 1.8 MB/s eta 0:00:19\n",
      "     --------- ------------------------------ 10.8/44.0 MB 1.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 10.9/44.0 MB 1.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 10.9/44.0 MB 1.8 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.1/44.0 MB 1.8 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.2/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.3/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.4/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.6/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.6/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.7/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.8/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 11.9/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 12.0/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 12.1/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 12.2/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 12.2/44.0 MB 1.9 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 12.4/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 12.4/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 12.5/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 12.6/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 12.6/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 12.7/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 12.8/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 12.9/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 13.0/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 13.1/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 13.2/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 13.3/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 13.4/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 13.4/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 13.5/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 13.6/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 13.7/44.0 MB 1.9 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 13.8/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 13.9/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 14.0/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 14.0/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 14.1/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 14.2/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 14.3/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 14.4/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 14.5/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 14.6/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 14.7/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 14.8/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 14.9/44.0 MB 1.9 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 15.0/44.0 MB 1.9 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 15.2/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 15.3/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 15.4/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 15.5/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 15.6/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 15.6/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 15.6/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 15.6/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 15.6/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 16.1/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 16.2/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     -------------- ------------------------- 16.2/44.0 MB 2.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 16.3/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     -------------- ------------------------- 16.3/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     -------------- ------------------------- 16.4/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     -------------- ------------------------- 16.5/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 16.5/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 16.6/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 16.7/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 16.7/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 16.8/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 16.9/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 16.9/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.0/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.2/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.2/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.3/44.0 MB 2.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.4/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.4/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.5/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 17.6/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 17.7/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 17.8/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 17.9/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.0/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.1/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.2/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.3/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.4/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.5/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.6/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 18.6/44.0 MB 1.9 MB/s eta 0:00:14\n",
      "     ----------------- ---------------------- 18.8/44.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 18.9/44.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.0/44.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.1/44.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.2/44.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.3/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.4/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.5/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.6/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 19.7/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 19.8/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 19.9/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 20.1/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 20.2/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 20.3/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 20.4/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 20.5/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 20.6/44.0 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 20.8/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------ --------------------- 20.9/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.0/44.0 MB 2.0 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.0/44.0 MB 2.0 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.0/44.0 MB 2.0 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.2/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.4/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.5/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.6/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.7/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.8/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.8/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 21.9/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     ------------------- -------------------- 22.0/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.1/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.2/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.3/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.3/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.4/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.6/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.6/44.0 MB 1.9 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 22.7/44.0 MB 1.9 MB/s eta 0:00:11\n",
      "     -------------------- ------------------- 22.8/44.0 MB 1.9 MB/s eta 0:00:11\n",
      "     -------------------- ------------------- 23.0/44.0 MB 1.9 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.1/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.3/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.4/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.5/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.6/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.7/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.8/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 23.9/44.0 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 24.1/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     --------------------- ------------------ 24.2/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 24.2/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 24.4/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 24.5/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 24.6/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 24.7/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 24.8/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 25.0/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 25.0/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 25.1/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 25.2/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 25.3/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 25.4/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 25.5/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 25.6/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 25.7/44.0 MB 2.0 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 25.8/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ----------------------- ---------------- 25.9/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ----------------------- ---------------- 26.1/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ----------------------- ---------------- 26.2/44.0 MB 2.0 MB/s eta 0:00:09\n",
      "     ----------------------- ---------------- 26.3/44.0 MB 2.0 MB/s eta 0:00:09\n",
      "     ----------------------- ---------------- 26.4/44.0 MB 2.0 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 26.6/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 26.7/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 26.7/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 26.8/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 27.0/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 27.1/44.0 MB 2.1 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 27.2/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 27.3/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 27.3/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 27.5/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 27.5/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 27.7/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 27.8/44.0 MB 2.2 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 27.8/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 27.9/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 27.9/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 28.1/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 28.1/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 28.2/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 28.4/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 28.5/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 28.6/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 28.7/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 28.8/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 28.9/44.0 MB 2.2 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 29.0/44.0 MB 2.1 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 29.2/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 29.3/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 29.4/44.0 MB 2.1 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 29.5/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 29.6/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 29.7/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 29.8/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 29.9/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.0/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.1/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.2/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.3/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.4/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.5/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.6/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.7/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 30.8/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 31.0/44.0 MB 2.2 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 31.1/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 31.2/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 31.3/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 31.5/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 31.5/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 31.7/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 31.8/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 31.9/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.0/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.1/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.2/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.3/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.4/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.5/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.6/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.7/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.8/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 32.9/44.0 MB 2.2 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 33.0/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.1/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.2/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.2/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.3/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.5/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.6/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.7/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.8/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 33.9/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 34.0/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.2/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.3/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.4/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.4/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.5/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.6/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.7/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.7/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.8/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 34.9/44.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 35.0/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 35.1/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 35.1/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.2/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.3/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.4/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.5/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.5/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.6/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.6/44.0 MB 2.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 35.7/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 35.8/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 35.9/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 36.0/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 36.0/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 36.1/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 36.2/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 36.3/44.0 MB 2.0 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 36.4/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 36.5/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 36.6/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 36.7/44.0 MB 2.0 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 36.9/44.0 MB 2.0 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 37.0/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 37.1/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 37.2/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 37.3/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 37.4/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 37.6/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 37.7/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 37.7/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 37.8/44.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 38.0/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 38.1/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 38.2/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 38.3/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 38.5/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 38.6/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 38.6/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 38.7/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 38.8/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 38.9/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 39.0/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 39.1/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 39.2/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 39.3/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 39.4/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 39.6/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 39.7/44.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 40.0/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 40.1/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 40.2/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 40.3/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 40.4/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 40.5/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 40.6/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 40.7/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 40.9/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 40.9/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 41.0/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 41.2/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 41.3/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 41.4/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 41.5/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 41.7/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 41.7/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 41.9/44.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 42.0/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.1/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.2/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.3/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.4/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.5/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.6/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.8/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.9/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.0/44.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.0/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.1/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.2/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.2/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.3/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.3/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.4/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.5/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.7/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.8/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.0/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.0/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.0/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.0/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.0/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.0/44.0 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 44.0/44.0 MB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (0.14.0)\n",
      "Collecting tqdm>=4.64.0\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 71.7/78.3 kB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 78.3/78.3 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (3.6.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from ultralytics) (1.13.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\venv\\torch\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\venv\\torch\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\venv\\torch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Installing collected packages: py-cpuinfo, tqdm, scipy, seaborn, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 scipy-1.11.2 seaborn-0.12.2 tqdm-4.66.1 ultralytics-8.0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOを使用するには， ultralyticsというライブラリを使用します．（この名前は研究機関の名前から来てたはず...）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，YOLOを読み込んで使用してみましょう．次のコードを実行してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\user\\venv\\torch\\tutorial\\aplication\\bus.jpg: 320x256 3 persons, 1 bus, 475.6ms\n",
      "Speed: 2.0ms preprocess, 475.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 256)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8l.pt\") #.ptファイルに，YOLOの重みデータが入っているので，公式からダウンロードして読み込み．\n",
    "#一度ダウンロードしたら，勝手にパスを通して，次回からはダウンロードなしで使える\n",
    "\n",
    "#ネットにある画像のパス\n",
    "source = \"https://ultralytics.com/images/bus.jpg\"\n",
    "\n",
    "#画像のパスとサイズ，分類結果を保存の有無などを引数にとる\n",
    "results = model.predict(source, save=True, imgsz=320, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完了したら，実行結果を確認してみましょう．tutorial\\aplication\\runs\\detect\\predictというフォルダが勝手に作られているので中身を確認してください．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOはv8に限りますが，このようにめっちゃ簡単に使用する事ができます．この調子で，他の機能も見てみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv8の機能としては，セグメンテーションというものを行うものがあります．これは，物体の形状すらも予測して，物体検出を行う機能のことです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt to 'yolov8l-seg.pt'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad8c69889634870aeb0e0a1b0735538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/88.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\user\\venv\\torch\\tutorial\\aplication\\bus.jpg: 320x256 3 persons, 1 bus, 529.7ms\n",
      "Speed: 2.0ms preprocess, 529.7ms inference, 8.1ms postprocess per image at shape (1, 3, 320, 256)\n",
      "Results saved to \u001b[1mruns\\segment\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8l-seg.pt\") #.ptファイルに，YOLOの重みデータが入っているので，公式からダウンロードして読み込み．\n",
    "#一度ダウンロードしたら，勝手にパスを通して，次回からはダウンロードなしで使える\n",
    "\n",
    "#ネットにある画像のパス\n",
    "source = \"https://ultralytics.com/images/bus.jpg\"\n",
    "\n",
    "#画像のパスとサイズ，分類結果を保存の有無などを引数にとる\n",
    "results = model.predict(source, save=True, imgsz=320, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行が完了すれば，tutorial\\aplication\\runs\\segment\\predictが作られていることを確認してください．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3，人数カウントカメラの裏側"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほんの少しですが，YOLOに触れることができたので，「人数カウントカメラ」というものを作ってみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらは，僕が高専祭で展示していたもので，プロコンブースの来場者の合計を数えるために制作しました．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この人数カウントカメラに必要な要素はズバリ一つ，画像の中に人が何人写っているかをYOLOに推論させることです．YOLOの推論の結果を画像以外の形で表示するには，以下のようにします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\user\\venv\\torch\\tutorial\\aplication\\bus.jpg: 320x256 3 persons, 1 bus, 488.4ms\n",
      "Speed: 2.0ms preprocess, 488.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box coordinates: tensor([  9.6144, 229.0865, 803.2972, 738.5203]), Object: bus\n",
      "Box coordinates: tensor([ 51.1157, 398.3147, 245.5587, 903.2975]), Object: person\n",
      "Box coordinates: tensor([664.6760, 390.3474, 809.2134, 878.1231]), Object: person\n",
      "Box coordinates: tensor([221.9324, 407.5237, 344.9286, 860.8000]), Object: person\n"
     ]
    }
   ],
   "source": [
    "source = \"https://ultralytics.com/images/bus.jpg\"\n",
    "model = YOLO('yolov8l.pt')\n",
    "\n",
    "results = model.predict(source,imgsz=320, conf=0.5)\n",
    "\n",
    "# results[0]から推論結果を取り出す\n",
    "result_object = results[0]\n",
    "\n",
    "# バウンディングボックスの座標を取得\n",
    "bounding_boxes = result_object.boxes.xyxy\n",
    "\n",
    "# クラスIDを取得\n",
    "class_ids = result_object.boxes.cls\n",
    "\n",
    "# クラス名の辞書を取得\n",
    "class_names_dict = result_object.names\n",
    "\n",
    "# バウンディングボックスとクラス名を組み合わせて表示\n",
    "for box, class_id in zip(bounding_boxes, class_ids):\n",
    "    class_name = class_names_dict[int(class_id)]\n",
    "    print(f\"Box coordinates: {box}, Object: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードの中で，「class_ids」というのが，写っている物体の内容を示しています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "bus\n",
      "tensor(0.)\n",
      "person\n",
      "tensor(0.)\n",
      "person\n",
      "tensor(0.)\n",
      "person\n"
     ]
    }
   ],
   "source": [
    "for id in class_ids:\n",
    "    print(id)\n",
    "    print(class_names_dict[int(id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで，わかるのは，ID=0で示されているのが，人ということであり，画像の中には，3人の人が写っています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではこれを応用してみましょう．写っているものがperson，つまり，ID=0のなら，カウントを1プラスするという処理を実行してみます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "\n",
    "for id in class_ids:\n",
    "    print(id)\n",
    "    if int(id)==0:\n",
    "        count+=1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで，「一枚の画像に写る」人数を数えることに成功しました．しかし，今回はカメラの映像から，人数を数える必要があるので，カメラの映像の推論を行う必要があります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下がそのコードです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b99d84a1bb24f92938b2a6c5b8abf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/21.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 378.6ms\n",
      "Speed: 4.0ms preprocess, 378.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 420.1ms\n",
      "Speed: 4.0ms preprocess, 420.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 378.7ms\n",
      "Speed: 2.0ms preprocess, 378.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 380.0ms\n",
      "Speed: 2.0ms preprocess, 380.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 357.0ms\n",
      "Speed: 2.0ms preprocess, 357.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 409.6ms\n",
      "Speed: 3.0ms preprocess, 409.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 358.6ms\n",
      "Speed: 3.7ms preprocess, 358.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 398.1ms\n",
      "Speed: 3.0ms preprocess, 398.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 373.6ms\n",
      "Speed: 2.0ms preprocess, 373.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 369.4ms\n",
      "Speed: 3.0ms preprocess, 369.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 369.9ms\n",
      "Speed: 3.0ms preprocess, 369.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 362.4ms\n",
      "Speed: 3.0ms preprocess, 362.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 378.1ms\n",
      "Speed: 2.0ms preprocess, 378.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 343.1ms\n",
      "Speed: 2.0ms preprocess, 343.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 355.3ms\n",
      "Speed: 3.0ms preprocess, 355.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 370.3ms\n",
      "Speed: 2.6ms preprocess, 370.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 368.8ms\n",
      "Speed: 3.1ms preprocess, 368.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 358.3ms\n",
      "Speed: 3.5ms preprocess, 358.3ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 414.2ms\n",
      "Speed: 2.5ms preprocess, 414.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 416.5ms\n",
      "Speed: 3.0ms preprocess, 416.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 398.6ms\n",
      "Speed: 4.3ms preprocess, 398.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 401.6ms\n",
      "Speed: 3.0ms preprocess, 401.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 383.2ms\n",
      "Speed: 3.0ms preprocess, 383.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 385.9ms\n",
      "Speed: 3.0ms preprocess, 385.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 382.0ms\n",
      "Speed: 3.0ms preprocess, 382.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 392.6ms\n",
      "Speed: 2.0ms preprocess, 392.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 423.3ms\n",
      "Speed: 3.6ms preprocess, 423.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 450.1ms\n",
      "Speed: 3.0ms preprocess, 450.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 414.3ms\n",
      "Speed: 3.0ms preprocess, 414.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 437.7ms\n",
      "Speed: 2.0ms preprocess, 437.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 409.0ms\n",
      "Speed: 3.0ms preprocess, 409.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 399.1ms\n",
      "Speed: 4.0ms preprocess, 399.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 388.7ms\n",
      "Speed: 2.0ms preprocess, 388.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 389.9ms\n",
      "Speed: 3.5ms preprocess, 389.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 426.8ms\n",
      "Speed: 3.0ms preprocess, 426.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 434.8ms\n",
      "Speed: 3.0ms preprocess, 434.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 439.8ms\n",
      "Speed: 3.5ms preprocess, 439.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 433.0ms\n",
      "Speed: 3.0ms preprocess, 433.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 410.1ms\n",
      "Speed: 3.0ms preprocess, 410.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 409.1ms\n",
      "Speed: 3.0ms preprocess, 409.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 388.9ms\n",
      "Speed: 4.0ms preprocess, 388.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 388.6ms\n",
      "Speed: 4.0ms preprocess, 388.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 386.6ms\n",
      "Speed: 3.0ms preprocess, 386.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 390.7ms\n",
      "Speed: 3.0ms preprocess, 390.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 396.7ms\n",
      "Speed: 3.0ms preprocess, 396.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 395.1ms\n",
      "Speed: 3.0ms preprocess, 395.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 382.0ms\n",
      "Speed: 3.0ms preprocess, 382.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 382.0ms\n",
      "Speed: 2.0ms preprocess, 382.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 429.5ms\n",
      "Speed: 3.0ms preprocess, 429.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 395.1ms\n",
      "Speed: 3.2ms preprocess, 395.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 toothbrush, 405.0ms\n",
      "Speed: 3.0ms preprocess, 405.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 457.9ms\n",
      "Speed: 3.0ms preprocess, 457.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 453.0ms\n",
      "Speed: 3.0ms preprocess, 453.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 459.4ms\n",
      "Speed: 3.0ms preprocess, 459.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 443.9ms\n",
      "Speed: 3.0ms preprocess, 443.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 458.6ms\n",
      "Speed: 3.0ms preprocess, 458.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 470.6ms\n",
      "Speed: 3.0ms preprocess, 470.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 435.1ms\n",
      "Speed: 3.0ms preprocess, 435.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 445.0ms\n",
      "Speed: 3.0ms preprocess, 445.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 442.3ms\n",
      "Speed: 3.0ms preprocess, 442.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 444.3ms\n",
      "Speed: 4.0ms preprocess, 444.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 450.6ms\n",
      "Speed: 3.0ms preprocess, 450.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 449.6ms\n",
      "Speed: 3.0ms preprocess, 449.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 445.8ms\n",
      "Speed: 4.0ms preprocess, 445.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 447.5ms\n",
      "Speed: 2.5ms preprocess, 447.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 452.9ms\n",
      "Speed: 3.0ms preprocess, 452.9ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 440.0ms\n",
      "Speed: 4.0ms preprocess, 440.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 447.5ms\n",
      "Speed: 3.0ms preprocess, 447.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 504.9ms\n",
      "Speed: 3.0ms preprocess, 504.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 457.4ms\n",
      "Speed: 4.0ms preprocess, 457.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 467.7ms\n",
      "Speed: 3.0ms preprocess, 467.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 461.7ms\n",
      "Speed: 3.0ms preprocess, 461.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 467.7ms\n",
      "Speed: 4.0ms preprocess, 467.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 467.2ms\n",
      "Speed: 3.0ms preprocess, 467.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 448.2ms\n",
      "Speed: 3.0ms preprocess, 448.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 461.9ms\n",
      "Speed: 4.0ms preprocess, 461.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 454.7ms\n",
      "Speed: 3.0ms preprocess, 454.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 588.4ms\n",
      "Speed: 4.0ms preprocess, 588.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 573.8ms\n",
      "Speed: 4.0ms preprocess, 573.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 528.4ms\n",
      "Speed: 3.0ms preprocess, 528.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 511.7ms\n",
      "Speed: 3.0ms preprocess, 511.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 481.3ms\n",
      "Speed: 5.0ms preprocess, 481.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 427.8ms\n",
      "Speed: 4.0ms preprocess, 427.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 430.1ms\n",
      "Speed: 3.1ms preprocess, 430.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 388.9ms\n",
      "Speed: 2.0ms preprocess, 388.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 403.8ms\n",
      "Speed: 3.0ms preprocess, 403.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 408.9ms\n",
      "Speed: 3.0ms preprocess, 408.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 428.2ms\n",
      "Speed: 4.0ms preprocess, 428.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 420.1ms\n",
      "Speed: 3.0ms preprocess, 420.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 467.0ms\n",
      "Speed: 2.0ms preprocess, 467.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 431.9ms\n",
      "Speed: 3.0ms preprocess, 431.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 451.8ms\n",
      "Speed: 3.0ms preprocess, 451.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 446.8ms\n",
      "Speed: 4.0ms preprocess, 446.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 handbag, 456.1ms\n",
      "Speed: 4.1ms preprocess, 456.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 417.1ms\n",
      "Speed: 3.0ms preprocess, 417.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 423.4ms\n",
      "Speed: 3.0ms preprocess, 423.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 467.3ms\n",
      "Speed: 3.0ms preprocess, 467.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 458.9ms\n",
      "Speed: 3.0ms preprocess, 458.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 434.5ms\n",
      "Speed: 3.0ms preprocess, 434.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 438.9ms\n",
      "Speed: 3.6ms preprocess, 438.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 478.2ms\n",
      "Speed: 3.0ms preprocess, 478.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 516.7ms\n",
      "Speed: 4.0ms preprocess, 516.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 475.3ms\n",
      "Speed: 2.0ms preprocess, 475.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 497.0ms\n",
      "Speed: 3.0ms preprocess, 497.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 457.7ms\n",
      "Speed: 3.0ms preprocess, 457.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 445.4ms\n",
      "Speed: 3.0ms preprocess, 445.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 434.3ms\n",
      "Speed: 3.0ms preprocess, 434.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 444.1ms\n",
      "Speed: 3.0ms preprocess, 444.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 476.8ms\n",
      "Speed: 4.0ms preprocess, 476.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 535.7ms\n",
      "Speed: 3.0ms preprocess, 535.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 471.0ms\n",
      "Speed: 3.5ms preprocess, 471.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 455.2ms\n",
      "Speed: 3.6ms preprocess, 455.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 473.6ms\n",
      "Speed: 5.0ms preprocess, 473.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 466.6ms\n",
      "Speed: 2.0ms preprocess, 466.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 458.6ms\n",
      "Speed: 3.0ms preprocess, 458.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 475.5ms\n",
      "Speed: 3.0ms preprocess, 475.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 461.2ms\n",
      "Speed: 3.0ms preprocess, 461.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 472.9ms\n",
      "Speed: 3.0ms preprocess, 472.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 481.1ms\n",
      "Speed: 3.0ms preprocess, 481.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 503.1ms\n",
      "Speed: 3.0ms preprocess, 503.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 460.0ms\n",
      "Speed: 3.0ms preprocess, 460.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 491.8ms\n",
      "Speed: 3.0ms preprocess, 491.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 515.5ms\n",
      "Speed: 4.0ms preprocess, 515.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 533.6ms\n",
      "Speed: 4.0ms preprocess, 533.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 499.8ms\n",
      "Speed: 3.0ms preprocess, 499.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 483.8ms\n",
      "Speed: 4.0ms preprocess, 483.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 476.6ms\n",
      "Speed: 3.0ms preprocess, 476.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 511.9ms\n",
      "Speed: 4.7ms preprocess, 511.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 567.7ms\n",
      "Speed: 3.0ms preprocess, 567.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 510.8ms\n",
      "Speed: 4.0ms preprocess, 510.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 513.5ms\n",
      "Speed: 4.0ms preprocess, 513.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 515.9ms\n",
      "Speed: 6.0ms preprocess, 515.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 504.9ms\n",
      "Speed: 5.0ms preprocess, 504.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 507.4ms\n",
      "Speed: 3.0ms preprocess, 507.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 520.2ms\n",
      "Speed: 4.0ms preprocess, 520.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 515.8ms\n",
      "Speed: 4.0ms preprocess, 515.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 554.4ms\n",
      "Speed: 4.0ms preprocess, 554.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 526.9ms\n",
      "Speed: 3.1ms preprocess, 526.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 538.0ms\n",
      "Speed: 4.0ms preprocess, 538.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 532.2ms\n",
      "Speed: 4.0ms preprocess, 532.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 536.1ms\n",
      "Speed: 4.0ms preprocess, 536.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 552.6ms\n",
      "Speed: 4.0ms preprocess, 552.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 593.8ms\n",
      "Speed: 4.0ms preprocess, 593.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 704.1ms\n",
      "Speed: 4.0ms preprocess, 704.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 807.7ms\n",
      "Speed: 5.0ms preprocess, 807.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 683.4ms\n",
      "Speed: 5.0ms preprocess, 683.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 603.2ms\n",
      "Speed: 5.1ms preprocess, 603.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 654.3ms\n",
      "Speed: 5.0ms preprocess, 654.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 682.4ms\n",
      "Speed: 6.0ms preprocess, 682.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 721.1ms\n",
      "Speed: 5.0ms preprocess, 721.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 815.7ms\n",
      "Speed: 6.0ms preprocess, 815.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 851.2ms\n",
      "Speed: 5.0ms preprocess, 851.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 687.7ms\n",
      "Speed: 4.0ms preprocess, 687.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 hot dog, 717.8ms\n",
      "Speed: 9.3ms preprocess, 717.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 721.4ms\n",
      "Speed: 6.0ms preprocess, 721.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 876.4ms\n",
      "Speed: 4.0ms preprocess, 876.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 933.7ms\n",
      "Speed: 7.0ms preprocess, 933.7ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 832.0ms\n",
      "Speed: 6.8ms preprocess, 832.0ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#モデルの読み込み(精度は低いが推論がはやい s モデルを使用)\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "#カメラを取得\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#カメラが映像を取得している間実行\n",
    "while cap.isOpened():\n",
    "    \n",
    "    #映像と，フレーム数をカメラカメラから取得\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "\n",
    "        #ここで推論\n",
    "        results = model(frame)\n",
    "\n",
    "        # 推論結果をプロットした画像を生成\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # それを表示\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # qボタンでループをぬける\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # カメラ映像の獲得に失敗すると，処理を強制終了\n",
    "        break\n",
    "\n",
    "#表示しているウィンドウの削除と，カメラの解放\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，これを先程のコードを用いて改造していきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 persons, 519.7ms\n",
      "Speed: 0.0ms preprocess, 519.7ms inference, 19.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 518.3ms\n",
      "Speed: 10.6ms preprocess, 518.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 445.4ms\n",
      "Speed: 2.0ms preprocess, 445.4ms inference, 17.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 455.3ms\n",
      "Speed: 1.8ms preprocess, 455.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 429.3ms\n",
      "Speed: 0.0ms preprocess, 429.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 419.9ms\n",
      "Speed: 1.4ms preprocess, 419.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 444.0ms\n",
      "Speed: 0.0ms preprocess, 444.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 435.1ms\n",
      "Speed: 0.0ms preprocess, 435.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 485.6ms\n",
      "Speed: 4.8ms preprocess, 485.6ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 428.6ms\n",
      "Speed: 3.0ms preprocess, 428.6ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 457.8ms\n",
      "Speed: 0.4ms preprocess, 457.8ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 548.0ms\n",
      "Speed: 8.0ms preprocess, 548.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 480.9ms\n",
      "Speed: 3.1ms preprocess, 480.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 480.6ms\n",
      "Speed: 3.6ms preprocess, 480.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 471.3ms\n",
      "Speed: 5.0ms preprocess, 471.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 481.4ms\n",
      "Speed: 0.0ms preprocess, 481.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 415.8ms\n",
      "Speed: 2.3ms preprocess, 415.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 445.8ms\n",
      "Speed: 0.0ms preprocess, 445.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 423.3ms\n",
      "Speed: 2.3ms preprocess, 423.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 419.6ms\n",
      "Speed: 3.1ms preprocess, 419.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 404.2ms\n",
      "Speed: 2.7ms preprocess, 404.2ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 439.5ms\n",
      "Speed: 5.0ms preprocess, 439.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 433.1ms\n",
      "Speed: 3.0ms preprocess, 433.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 427.0ms\n",
      "Speed: 2.7ms preprocess, 427.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 430.4ms\n",
      "Speed: 0.0ms preprocess, 430.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 416.1ms\n",
      "Speed: 0.0ms preprocess, 416.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 418.6ms\n",
      "Speed: 3.0ms preprocess, 418.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 426.9ms\n",
      "Speed: 4.6ms preprocess, 426.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 451.8ms\n",
      "Speed: 4.1ms preprocess, 451.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 419.0ms\n",
      "Speed: 0.0ms preprocess, 419.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 427.7ms\n",
      "Speed: 3.4ms preprocess, 427.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 423.4ms\n",
      "Speed: 2.0ms preprocess, 423.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 418.4ms\n",
      "Speed: 4.4ms preprocess, 418.4ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 442.3ms\n",
      "Speed: 3.7ms preprocess, 442.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 425.7ms\n",
      "Speed: 4.5ms preprocess, 425.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 440.4ms\n",
      "Speed: 5.4ms preprocess, 440.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 440.2ms\n",
      "Speed: 4.5ms preprocess, 440.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 438.1ms\n",
      "Speed: 3.9ms preprocess, 438.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 396.4ms\n",
      "Speed: 4.6ms preprocess, 396.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 425.5ms\n",
      "Speed: 1.4ms preprocess, 425.5ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 440.4ms\n",
      "Speed: 0.0ms preprocess, 440.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 408.4ms\n",
      "Speed: 5.9ms preprocess, 408.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 435.0ms\n",
      "Speed: 0.0ms preprocess, 435.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 459.3ms\n",
      "Speed: 4.5ms preprocess, 459.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 422.9ms\n",
      "Speed: 2.0ms preprocess, 422.9ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 392.4ms\n",
      "Speed: 4.5ms preprocess, 392.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 431.4ms\n",
      "Speed: 2.5ms preprocess, 431.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 437.5ms\n",
      "Speed: 4.3ms preprocess, 437.5ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 438.5ms\n",
      "Speed: 0.0ms preprocess, 438.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 425.1ms\n",
      "Speed: 2.6ms preprocess, 425.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 442.0ms\n",
      "Speed: 4.2ms preprocess, 442.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 417.5ms\n",
      "Speed: 0.0ms preprocess, 417.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 2 cell phones, 428.9ms\n",
      "Speed: 3.7ms preprocess, 428.9ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 422.9ms\n",
      "Speed: 3.7ms preprocess, 422.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 415.2ms\n",
      "Speed: 3.8ms preprocess, 415.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 437.3ms\n",
      "Speed: 3.6ms preprocess, 437.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 2 cell phones, 418.4ms\n",
      "Speed: 4.4ms preprocess, 418.4ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 462.7ms\n",
      "Speed: 3.9ms preprocess, 462.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 394.2ms\n",
      "Speed: 6.1ms preprocess, 394.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 2 cell phones, 435.5ms\n",
      "Speed: 1.8ms preprocess, 435.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 437.7ms\n",
      "Speed: 3.6ms preprocess, 437.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 459.9ms\n",
      "Speed: 5.9ms preprocess, 459.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 412.1ms\n",
      "Speed: 0.0ms preprocess, 412.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 415.5ms\n",
      "Speed: 2.8ms preprocess, 415.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 421.7ms\n",
      "Speed: 3.4ms preprocess, 421.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 429.6ms\n",
      "Speed: 4.6ms preprocess, 429.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 436.5ms\n",
      "Speed: 4.1ms preprocess, 436.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 chair, 1 cell phone, 404.4ms\n",
      "Speed: 2.5ms preprocess, 404.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 chair, 1 cell phone, 444.4ms\n",
      "Speed: 5.2ms preprocess, 444.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 427.6ms\n",
      "Speed: 0.0ms preprocess, 427.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 432.4ms\n",
      "Speed: 3.4ms preprocess, 432.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 431.9ms\n",
      "Speed: 2.3ms preprocess, 431.9ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 wine glass, 1 cup, 1 cell phone, 433.5ms\n",
      "Speed: 4.9ms preprocess, 433.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 wine glass, 428.1ms\n",
      "Speed: 3.6ms preprocess, 428.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 438.9ms\n",
      "Speed: 1.0ms preprocess, 438.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 459.2ms\n",
      "Speed: 3.8ms preprocess, 459.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 book, 431.4ms\n",
      "Speed: 1.7ms preprocess, 431.4ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cell phone, 428.9ms\n",
      "Speed: 1.3ms preprocess, 428.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 423.0ms\n",
      "Speed: 2.9ms preprocess, 423.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 448.7ms\n",
      "Speed: 4.3ms preprocess, 448.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 418.6ms\n",
      "Speed: 5.6ms preprocess, 418.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 431.4ms\n",
      "Speed: 1.4ms preprocess, 431.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 460.3ms\n",
      "Speed: 3.0ms preprocess, 460.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 447.9ms\n",
      "Speed: 3.4ms preprocess, 447.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 414.0ms\n",
      "Speed: 1.8ms preprocess, 414.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 440.4ms\n",
      "Speed: 3.0ms preprocess, 440.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 419.6ms\n",
      "Speed: 0.0ms preprocess, 419.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 baseball bat, 434.3ms\n",
      "Speed: 3.7ms preprocess, 434.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 wine glass, 420.3ms\n",
      "Speed: 3.4ms preprocess, 420.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 2 cups, 439.1ms\n",
      "Speed: 1.0ms preprocess, 439.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cup, 1 vase, 443.9ms\n",
      "Speed: 0.0ms preprocess, 443.9ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cup, 431.8ms\n",
      "Speed: 3.5ms preprocess, 431.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cup, 426.8ms\n",
      "Speed: 4.5ms preprocess, 426.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cup, 429.2ms\n",
      "Speed: 1.9ms preprocess, 429.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 2 cups, 440.3ms\n",
      "Speed: 3.3ms preprocess, 440.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cup, 424.7ms\n",
      "Speed: 0.0ms preprocess, 424.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cup, 463.6ms\n",
      "Speed: 5.8ms preprocess, 463.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 2 cups, 417.4ms\n",
      "Speed: 4.4ms preprocess, 417.4ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 2 cups, 440.6ms\n",
      "Speed: 2.4ms preprocess, 440.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cup, 423.2ms\n",
      "Speed: 2.1ms preprocess, 423.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cup, 417.6ms\n",
      "Speed: 5.5ms preprocess, 417.6ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cup, 422.8ms\n",
      "Speed: 7.1ms preprocess, 422.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cup, 427.4ms\n",
      "Speed: 3.0ms preprocess, 427.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cup, 471.0ms\n",
      "Speed: 2.1ms preprocess, 471.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 donut, 439.5ms\n",
      "Speed: 0.0ms preprocess, 439.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 443.0ms\n",
      "Speed: 1.9ms preprocess, 443.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 433.6ms\n",
      "Speed: 2.3ms preprocess, 433.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cell phone, 447.4ms\n",
      "Speed: 5.1ms preprocess, 447.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 428.2ms\n",
      "Speed: 2.9ms preprocess, 428.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 cell phone, 445.4ms\n",
      "Speed: 1.6ms preprocess, 445.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 1 cell phone, 463.5ms\n",
      "Speed: 3.7ms preprocess, 463.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 cell phone, 450.5ms\n",
      "Speed: 1.0ms preprocess, 450.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 cell phone, 418.6ms\n",
      "Speed: 5.8ms preprocess, 418.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 444.6ms\n",
      "Speed: 2.1ms preprocess, 444.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 429.8ms\n",
      "Speed: 0.0ms preprocess, 429.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 438.7ms\n",
      "Speed: 3.4ms preprocess, 438.7ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 437.9ms\n",
      "Speed: 4.4ms preprocess, 437.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 457.0ms\n",
      "Speed: 1.5ms preprocess, 457.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 442.2ms\n",
      "Speed: 0.0ms preprocess, 442.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 429.4ms\n",
      "Speed: 5.9ms preprocess, 429.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 448.1ms\n",
      "Speed: 3.9ms preprocess, 448.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 414.3ms\n",
      "Speed: 2.4ms preprocess, 414.3ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 449.9ms\n",
      "Speed: 2.8ms preprocess, 449.9ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 458.0ms\n",
      "Speed: 3.8ms preprocess, 458.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cell phone, 448.0ms\n",
      "Speed: 2.0ms preprocess, 448.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 1 cell phone, 435.7ms\n",
      "Speed: 3.0ms preprocess, 435.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 443.6ms\n",
      "Speed: 5.8ms preprocess, 443.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 432.3ms\n",
      "Speed: 2.5ms preprocess, 432.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 441.5ms\n",
      "Speed: 0.0ms preprocess, 441.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 436.3ms\n",
      "Speed: 1.1ms preprocess, 436.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 448.6ms\n",
      "Speed: 2.8ms preprocess, 448.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 440.3ms\n",
      "Speed: 3.7ms preprocess, 440.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 466.4ms\n",
      "Speed: 2.9ms preprocess, 466.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 446.3ms\n",
      "Speed: 2.6ms preprocess, 446.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 430.4ms\n",
      "Speed: 3.4ms preprocess, 430.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 437.6ms\n",
      "Speed: 3.7ms preprocess, 437.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 454.4ms\n",
      "Speed: 4.2ms preprocess, 454.4ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 443.6ms\n",
      "Speed: 5.8ms preprocess, 443.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 467.1ms\n",
      "Speed: 2.7ms preprocess, 467.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 438.7ms\n",
      "Speed: 5.1ms preprocess, 438.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 2 cell phones, 422.3ms\n",
      "Speed: 2.7ms preprocess, 422.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 452.2ms\n",
      "Speed: 0.0ms preprocess, 452.2ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 427.8ms\n",
      "Speed: 0.0ms preprocess, 427.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 1 cell phone, 445.2ms\n",
      "Speed: 3.2ms preprocess, 445.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 441.6ms\n",
      "Speed: 4.2ms preprocess, 441.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 455.7ms\n",
      "Speed: 0.0ms preprocess, 455.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 436.2ms\n",
      "Speed: 6.3ms preprocess, 436.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 433.7ms\n",
      "Speed: 2.6ms preprocess, 433.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 cell phone, 449.6ms\n",
      "Speed: 0.0ms preprocess, 449.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 424.0ms\n",
      "Speed: 3.1ms preprocess, 424.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 433.4ms\n",
      "Speed: 2.4ms preprocess, 433.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 437.5ms\n",
      "Speed: 1.9ms preprocess, 437.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 476.4ms\n",
      "Speed: 4.3ms preprocess, 476.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 430.5ms\n",
      "Speed: 2.9ms preprocess, 430.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 464.5ms\n",
      "Speed: 5.0ms preprocess, 464.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 435.2ms\n",
      "Speed: 3.3ms preprocess, 435.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 438.9ms\n",
      "Speed: 5.3ms preprocess, 438.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 430.4ms\n",
      "Speed: 0.0ms preprocess, 430.4ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 501.3ms\n",
      "Speed: 3.9ms preprocess, 501.3ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 465.1ms\n",
      "Speed: 4.1ms preprocess, 465.1ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 472.1ms\n",
      "Speed: 0.0ms preprocess, 472.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 466.3ms\n",
      "Speed: 2.1ms preprocess, 466.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 444.8ms\n",
      "Speed: 3.9ms preprocess, 444.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 481.5ms\n",
      "Speed: 0.0ms preprocess, 481.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 450.8ms\n",
      "Speed: 5.6ms preprocess, 450.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 511.7ms\n",
      "Speed: 6.9ms preprocess, 511.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 461.5ms\n",
      "Speed: 3.3ms preprocess, 461.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 475.3ms\n",
      "Speed: 1.2ms preprocess, 475.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 463.6ms\n",
      "Speed: 0.0ms preprocess, 463.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 476.1ms\n",
      "Speed: 0.0ms preprocess, 476.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 454.8ms\n",
      "Speed: 3.0ms preprocess, 454.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 494.1ms\n",
      "Speed: 2.9ms preprocess, 494.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 461.4ms\n",
      "Speed: 0.0ms preprocess, 461.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 477.1ms\n",
      "Speed: 4.4ms preprocess, 477.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 463.2ms\n",
      "Speed: 0.0ms preprocess, 463.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 464.9ms\n",
      "Speed: 4.8ms preprocess, 464.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cell phone, 462.4ms\n",
      "Speed: 3.0ms preprocess, 462.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 475.3ms\n",
      "Speed: 4.4ms preprocess, 475.3ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 480.5ms\n",
      "Speed: 0.0ms preprocess, 480.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 remote, 467.1ms\n",
      "Speed: 4.8ms preprocess, 467.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 444.4ms\n",
      "Speed: 2.5ms preprocess, 444.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 480.4ms\n",
      "Speed: 0.0ms preprocess, 480.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 471.0ms\n",
      "Speed: 3.0ms preprocess, 471.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 484.4ms\n",
      "Speed: 4.4ms preprocess, 484.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 483.0ms\n",
      "Speed: 1.0ms preprocess, 483.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 470.6ms\n",
      "Speed: 4.5ms preprocess, 470.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 449.7ms\n",
      "Speed: 3.1ms preprocess, 449.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 457.1ms\n",
      "Speed: 3.1ms preprocess, 457.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 445.3ms\n",
      "Speed: 1.5ms preprocess, 445.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 458.5ms\n",
      "Speed: 5.4ms preprocess, 458.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 457.2ms\n",
      "Speed: 3.1ms preprocess, 457.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 509.8ms\n",
      "Speed: 3.0ms preprocess, 509.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 455.0ms\n",
      "Speed: 4.1ms preprocess, 455.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 474.0ms\n",
      "Speed: 4.2ms preprocess, 474.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 465.1ms\n",
      "Speed: 0.0ms preprocess, 465.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 463.4ms\n",
      "Speed: 3.0ms preprocess, 463.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 7 persons, 450.6ms\n",
      "Speed: 4.6ms preprocess, 450.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 482.0ms\n",
      "Speed: 4.3ms preprocess, 482.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 503.7ms\n",
      "Speed: 2.2ms preprocess, 503.7ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 489.4ms\n",
      "Speed: 0.0ms preprocess, 489.4ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 454.4ms\n",
      "Speed: 4.4ms preprocess, 454.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 6 persons, 470.5ms\n",
      "Speed: 0.0ms preprocess, 470.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 5 persons, 469.0ms\n",
      "Speed: 0.0ms preprocess, 469.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 492.3ms\n",
      "Speed: 3.0ms preprocess, 492.3ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 489.2ms\n",
      "Speed: 0.0ms preprocess, 489.2ms inference, 9.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 491.7ms\n",
      "Speed: 5.0ms preprocess, 491.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 460.1ms\n",
      "Speed: 3.3ms preprocess, 460.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 4 persons, 1 tie, 473.6ms\n",
      "Speed: 3.2ms preprocess, 473.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 452.3ms\n",
      "Speed: 3.7ms preprocess, 452.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 tv, 462.9ms\n",
      "Speed: 3.1ms preprocess, 462.9ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 463.2ms\n",
      "Speed: 5.3ms preprocess, 463.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 493.6ms\n",
      "Speed: 1.0ms preprocess, 493.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 478.7ms\n",
      "Speed: 0.0ms preprocess, 478.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 479.8ms\n",
      "Speed: 2.6ms preprocess, 479.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 460.3ms\n",
      "Speed: 3.3ms preprocess, 460.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 471.6ms\n",
      "Speed: 4.5ms preprocess, 471.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 463.3ms\n",
      "Speed: 1.5ms preprocess, 463.3ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 559.5ms\n",
      "Speed: 0.0ms preprocess, 559.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 472.1ms\n",
      "Speed: 3.0ms preprocess, 472.1ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 507.0ms\n",
      "Speed: 2.2ms preprocess, 507.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#モデルの読み込み(精度は低いが推論がはやい s モデルを使用)\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "#カメラを取得\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#カメラが映像を取得している間実行\n",
    "while cap.isOpened():\n",
    "    \n",
    "    #画像と，フレーム数をカメラカメラから取得\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "\n",
    "        #1フレームに写る人の数を格納する変数\n",
    "        count=0\n",
    "\n",
    "        #ここで推論\n",
    "        results = model(frame)\n",
    "\n",
    "        # 推論結果をプロットした画像を生成\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # それを表示\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # results[0]から推論結果を取り出す\n",
    "        result_object = results[0]\n",
    "\n",
    "        # クラスIDを取得\n",
    "        class_ids = result_object.boxes.cls\n",
    "\n",
    "        # クラス名の辞書を取得\n",
    "        class_names_dict = result_object.names\n",
    "\n",
    "        #すべての被写体のIDに対して処理\n",
    "        for id in class_ids:\n",
    "            #もし，ID=0つまりpersonなら実行\n",
    "            if int(id)==0:\n",
    "                print(class_names_dict[int(id)])\n",
    "                count+=1\n",
    "\n",
    "        #人数を表示\n",
    "        print(count)\n",
    "\n",
    "        #リセット\n",
    "        count=0\n",
    "\n",
    "        # qボタンでループをぬける\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # カメラ映像の獲得に失敗すると，処理を強制終了\n",
    "        break\n",
    "\n",
    "#表示しているウィンドウの削除と，カメラの解放\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログを見てみると，「person 1」みたいなのが表示されていると思います．それならば成功です．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで，ある1フレームにおける人数のカウントは実装完了です．しかし，人数カウントカメラは，来場者の合計（つまり，今まで何人入ってきたか）を算出するカメラなので，これだけでは不十分です．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来場者の合計を求めるには，前回のフレームに写る人数に対して，カメラに写る人が何人増えたかを記録して，そこから求める必要があります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "言葉では伝わりにくいので，次のコードで示します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 393.9ms\n",
      "Speed: 3.0ms preprocess, 393.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 395.6ms\n",
      "Speed: 3.0ms preprocess, 395.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 423.6ms\n",
      "Speed: 3.0ms preprocess, 423.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 418.3ms\n",
      "Speed: 3.0ms preprocess, 418.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 462.5ms\n",
      "Speed: 3.7ms preprocess, 462.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 398.6ms\n",
      "Speed: 2.1ms preprocess, 398.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 391.1ms\n",
      "Speed: 3.5ms preprocess, 391.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 374.3ms\n",
      "Speed: 3.2ms preprocess, 374.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 418.5ms\n",
      "Speed: 3.0ms preprocess, 418.5ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 452.9ms\n",
      "Speed: 3.0ms preprocess, 452.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 462.9ms\n",
      "Speed: 4.0ms preprocess, 462.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 506.9ms\n",
      "Speed: 2.0ms preprocess, 506.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 423.7ms\n",
      "Speed: 4.0ms preprocess, 423.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 426.0ms\n",
      "Speed: 3.0ms preprocess, 426.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 426.4ms\n",
      "Speed: 3.0ms preprocess, 426.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 431.0ms\n",
      "Speed: 5.0ms preprocess, 431.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 419.2ms\n",
      "Speed: 1.8ms preprocess, 419.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 408.5ms\n",
      "Speed: 3.0ms preprocess, 408.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 475.2ms\n",
      "Speed: 3.0ms preprocess, 475.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 664.4ms\n",
      "Speed: 7.0ms preprocess, 664.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 534.3ms\n",
      "Speed: 8.0ms preprocess, 534.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 455.2ms\n",
      "Speed: 3.0ms preprocess, 455.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 439.2ms\n",
      "Speed: 2.8ms preprocess, 439.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 432.9ms\n",
      "Speed: 3.0ms preprocess, 432.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 433.9ms\n",
      "Speed: 3.0ms preprocess, 433.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 497.1ms\n",
      "Speed: 2.0ms preprocess, 497.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 578.4ms\n",
      "Speed: 7.0ms preprocess, 578.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 439.5ms\n",
      "Speed: 2.3ms preprocess, 439.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 439.2ms\n",
      "Speed: 3.0ms preprocess, 439.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 438.4ms\n",
      "Speed: 3.0ms preprocess, 438.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 449.7ms\n",
      "Speed: 3.0ms preprocess, 449.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 433.8ms\n",
      "Speed: 3.0ms preprocess, 433.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 426.9ms\n",
      "Speed: 3.0ms preprocess, 426.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 528.3ms\n",
      "Speed: 3.0ms preprocess, 528.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 439.9ms\n",
      "Speed: 3.0ms preprocess, 439.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 435.9ms\n",
      "Speed: 4.0ms preprocess, 435.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 421.5ms\n",
      "Speed: 3.0ms preprocess, 421.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 439.6ms\n",
      "Speed: 3.0ms preprocess, 439.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 419.5ms\n",
      "Speed: 4.0ms preprocess, 419.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 418.4ms\n",
      "Speed: 3.0ms preprocess, 418.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 656.7ms\n",
      "Speed: 3.0ms preprocess, 656.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 609.5ms\n",
      "Speed: 9.3ms preprocess, 609.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 460.7ms\n",
      "Speed: 3.0ms preprocess, 460.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tie, 449.4ms\n",
      "Speed: 4.0ms preprocess, 449.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tie, 437.4ms\n",
      "Speed: 3.4ms preprocess, 437.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 442.8ms\n",
      "Speed: 2.0ms preprocess, 442.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 456.9ms\n",
      "Speed: 5.5ms preprocess, 456.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 544.4ms\n",
      "Speed: 4.0ms preprocess, 544.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 421.3ms\n",
      "Speed: 2.0ms preprocess, 421.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 432.9ms\n",
      "Speed: 4.0ms preprocess, 432.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 429.0ms\n",
      "Speed: 3.0ms preprocess, 429.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 463.5ms\n",
      "Speed: 2.6ms preprocess, 463.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 507.1ms\n",
      "Speed: 2.6ms preprocess, 507.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 514.8ms\n",
      "Speed: 3.5ms preprocess, 514.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 539.8ms\n",
      "Speed: 89.5ms preprocess, 539.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 511.6ms\n",
      "Speed: 3.6ms preprocess, 511.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 520.0ms\n",
      "Speed: 3.0ms preprocess, 520.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 602.4ms\n",
      "Speed: 4.0ms preprocess, 602.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 638.2ms\n",
      "Speed: 3.0ms preprocess, 638.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 732.1ms\n",
      "Speed: 3.0ms preprocess, 732.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 601.8ms\n",
      "Speed: 5.0ms preprocess, 601.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 586.4ms\n",
      "Speed: 6.0ms preprocess, 586.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 562.2ms\n",
      "Speed: 5.0ms preprocess, 562.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 595.2ms\n",
      "Speed: 4.1ms preprocess, 595.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 804.6ms\n",
      "Speed: 12.0ms preprocess, 804.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 731.3ms\n",
      "Speed: 3.0ms preprocess, 731.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "2\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 763.2ms\n",
      "Speed: 5.0ms preprocess, 763.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 600.8ms\n",
      "Speed: 3.0ms preprocess, 600.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 762.9ms\n",
      "Speed: 4.1ms preprocess, 762.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 677.6ms\n",
      "Speed: 4.0ms preprocess, 677.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 764.5ms\n",
      "Speed: 31.7ms preprocess, 764.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 649.7ms\n",
      "Speed: 5.0ms preprocess, 649.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 610.1ms\n",
      "Speed: 4.0ms preprocess, 610.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 674.2ms\n",
      "Speed: 4.0ms preprocess, 674.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 562.5ms\n",
      "Speed: 4.0ms preprocess, 562.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 535.8ms\n",
      "Speed: 3.2ms preprocess, 535.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 532.4ms\n",
      "Speed: 3.0ms preprocess, 532.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 519.2ms\n",
      "Speed: 3.0ms preprocess, 519.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 525.5ms\n",
      "Speed: 3.0ms preprocess, 525.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 513.3ms\n",
      "Speed: 4.0ms preprocess, 513.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 499.5ms\n",
      "Speed: 2.0ms preprocess, 499.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 587.8ms\n",
      "Speed: 3.0ms preprocess, 587.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 469.8ms\n",
      "Speed: 2.0ms preprocess, 469.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 438.3ms\n",
      "Speed: 3.0ms preprocess, 438.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 435.9ms\n",
      "Speed: 3.0ms preprocess, 435.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 447.6ms\n",
      "Speed: 5.0ms preprocess, 447.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "1\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[39m#ここで推論\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m results \u001b[39m=\u001b[39m model(frame)\n\u001b[0;32m     30\u001b[0m \u001b[39m# 推論結果をプロットした画像を生成\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m#annotated_frame = results[0].plot() #処理が重いならここを消してもよい\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[39m# results[0]から推論結果を取り出す\u001b[39;00m\n\u001b[0;32m     37\u001b[0m result_object \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\engine\\model.py:96\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, source\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     95\u001b[0m     \u001b[39m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(source, stream, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\engine\\model.py:238\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m prompts \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m'\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\engine\\predictor.py:194\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:43\u001b[0m, in \u001b[0;36m_DecoratorContextManager._wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 43\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     45\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\engine\\predictor.py:253\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 253\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference(im, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[39m# Postprocess\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m2\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\engine\\predictor.py:133\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minference\u001b[39m(\u001b[39mself\u001b[39m, im, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    131\u001b[0m     visualize \u001b[39m=\u001b[39m increment_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir \u001b[39m/\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstem,\n\u001b[0;32m    132\u001b[0m                                mkdir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mvisualize \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type\u001b[39m.\u001b[39mtensor) \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:333\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize)\u001b[0m\n\u001b[0;32m    330\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_module:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im, augment\u001b[39m=\u001b[39maugment, visualize\u001b[39m=\u001b[39mvisualize) \u001b[39mif\u001b[39;00m augment \u001b[39mor\u001b[39;00m visualize \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im)\n\u001b[0;32m    334\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 45\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[0;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[1;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[0;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m---> 82\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[0;32m     83\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:181\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m--> 181\u001b[0m y\u001b[39m.\u001b[39;49mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;49;00m m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm)\n\u001b[0;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:181\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m--> 181\u001b[0m y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[0;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:283\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    282\u001b[0m     \u001b[39m\"\"\"'forward()' applies the YOLOv5 FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv1(x))\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:42\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     41\u001b[0m     \u001b[39m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\activation.py:395\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 395\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msilu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2058\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2056\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, inplace\u001b[39m=\u001b[39minplace)\n\u001b[0;32m   2057\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2058\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49msilu_(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   2059\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39msilu(\u001b[39minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#モデルの読み込み(精度は低いが推論がはやい s モデルを使用)\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "#カメラを取得\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#今まで写って来た人の合計\n",
    "sum=0\n",
    "\n",
    "#前回のフレームに写っていた人の数を格納する変数\n",
    "before_count=0\n",
    "\n",
    "#カメラが映像を取得している間実行\n",
    "while cap.isOpened():\n",
    "    \n",
    "    #画像と，フレーム数をカメラカメラから取得\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "\n",
    "        #1フレームに写る人の数を格納する変数\n",
    "        count=0\n",
    "\n",
    "        #ここで推論\n",
    "        results = model(frame)\n",
    "\n",
    "        # 推論結果をプロットした画像を生成\n",
    "        annotated_frame = results[0].plot() #処理が重いならここを消してもよい\n",
    "\n",
    "        # それを表示\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame) #処理が重いならここを消してもよい\n",
    "\n",
    "        # results[0]から推論結果を取り出す\n",
    "        result_object = results[0]\n",
    "\n",
    "        # クラスIDを取得\n",
    "        class_ids = result_object.boxes.cls\n",
    "\n",
    "        # クラス名の辞書を取得\n",
    "        class_names_dict = result_object.names\n",
    "\n",
    "        #すべての被写体のIDに対して処理\n",
    "        for id in class_ids:\n",
    "            #もし，ID=0つまりpersonなら実行\n",
    "            if int(id)==0:\n",
    "                print(class_names_dict[int(id)])\n",
    "                count+=1\n",
    "        \n",
    "        #もし，写る人数が現在から増えたら，それが訪れた人の差分となる\n",
    "        if count>before_count:\n",
    "            sum+=count-before_count\n",
    "\n",
    "        #推論が終われば，「今のカウント」は，「前回のカウント」に変わる\n",
    "        #「今日」という日も明日には「昨日」になるように（？）\n",
    "        before_count=count\n",
    "\n",
    "        #今のフレームに写る人数を表示\n",
    "        print(count)\n",
    "\n",
    "        #今までの人数の合計を表示\n",
    "        print(\"sum:\",sum)\n",
    "\n",
    "        #リセット\n",
    "        count=0\n",
    "\n",
    "        #処理が重いならここを消す\n",
    "        ###########################################\n",
    "        # qボタンでループをぬける\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"): \n",
    "            break \n",
    "        else: \n",
    "        # カメラ映像の獲得に失敗すると，処理を強制終了\n",
    "            break \n",
    "        ###########################################\n",
    "\n",
    "#表示しているウィンドウの削除と，カメラの解放\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カメラの前から消えたり，写ったりしてみてください．「sum ○○」のカウントが増えていると思います．これで，成功です．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで，講習は終了となります．お疲れ様でした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15ceeb7393f0aff2609f088f7fc6d439204a45655252d34f7ade3b35005ea835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
