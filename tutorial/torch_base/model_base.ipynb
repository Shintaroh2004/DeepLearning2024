{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第4回 モデルの構築"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はいよいよモデルの構築に入っていきます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルとはNN(ニューラルネットワーク)全般のことを指します。NNには種類がいくつかあり、有名どころではCNN（放送局?）やRNN、発展としてGANやLSTMなどがありますが、これらも一般にはモデルと呼ばれます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchのモデルの構築には、torchの中のnn.Moduleクラスを利用することがほとんどです。以下のコードはそのモデル構築の一例を示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#nn.Moduleクラスを親にして、モデルを定義する\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        #super().__init__()は、親クラスのメソッドやフィールドの使用に不可欠\n",
    "        super().__init__()\n",
    "        #二次元のデータを一次元にする\n",
    "        self.flatten = nn.Flatten()\n",
    "        #ここで、重みを含んだ層を定義する\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            #28*28=784の入力→512の出力（この入出力の数を間違えると動作しない）\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            #512の入力→512の出力\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            #512の入力→10の最終出力\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    #注目3\n",
    "    def forward(self, x):\n",
    "        #二次元→一次元\n",
    "        x = self.flatten(x)\n",
    "        #入力データxを入れた時の最終出力をlogitsに代入\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、モデルの定義は完了です。このモデルのクラスのインスタンスを制作すれば、モデルの実装は完了します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、このモデルにランダムな二次元のデータを入力してみましょう。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際にモデルに値を入力する場合は、モデルをまるで関数かのように扱って構いません。以下のコードを見ればわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0190, -0.0991, -0.0045,  0.1534, -0.0401,  0.0489, -0.0955, -0.1130,\n",
      "          0.0308,  0.0116]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0991, 0.0914, 0.1005, 0.1177, 0.0970, 0.1060, 0.0918, 0.0902, 0.1041,\n",
      "         0.1021]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted class: tensor([3])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28)\n",
    "#modelのforwardの戻り値が代入される（関数みたい）\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "#ソフトマックス関数を用いて、出力を0から1までの値に直す\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probab)\n",
    "#何番目の要素が最大か示す\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、レイヤーについて"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルは複数の層（レイヤー）で構成されます。ここでは、さっきのモデルで使用された層について解説します。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フラット層...データの次元を一次元にする層。Pytorchでは、torch.nn.Flatten()で示される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 784])\n",
      "torch.Size([1, 784])\n",
      "torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(1,28,28)\n",
    "print(input_image.size())\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "flatten2=torch.flatten(input_image)\n",
    "views=input_image.view(-1,784)\n",
    "print(views.size())\n",
    "print(flatten2.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、28*28の二次元のデータを一次元配列に変換できていますね。しかし、以下の場合はどうでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おいおい、[3,784]の二次元のデータになってんじゃねーか?!って思うかもしれません。しかし、問題はありません。この３って数は「チャネル数」とも呼ばれ、フラット化だけでは一次元に直せない次元のデータです。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このチャンネル数を見かける場面とすれば、jpg画像データの学習の時くらいです。jpg画像データのチャネル数は３、pngの場合はチャネル数は4、グレースケールの画像の場合はチャネル数は１になります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このチャネル数は、データの構成要素の数などを示します。jpg画像はRGBやGBRの3要素、pngはRGBAの4要素、グレースケールは黒(0)から白(1)までの間の数値1要素で構成されるので、それに対応したチャネル数となります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかし、そもそもなぜフラット化をする必要があるのでしょうか？答えは線形層の入力にあります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形層...nn.Linearで定義される層。重み、バイアスを含む一次元配列の層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "#これではエラーが出ません\n",
    "print(flat_image.size())\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この線形層に二次元のデータを入力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (84x28 and 784x20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#しかし、これはエラーが出ます\u001b[39;00m\n\u001b[0;32m      2\u001b[0m error_tensor\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mrand(\u001b[39m3\u001b[39m,\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m hidden2\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39;49mLinear(\u001b[39m28\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m28\u001b[39;49m,\u001b[39m20\u001b[39;49m)(error_tensor)\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (84x28 and 784x20)"
     ]
    }
   ],
   "source": [
    "#しかし、これはエラーが出ます\n",
    "error_tensor=torch.rand(3,28,28)\n",
    "hidden2=nn.Linear(28*28,20)(error_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラー文を見てみると、shape can't be multiplied と書いてあり、形が合っていないとの指摘がされていることがわかります。つまりは、Linear層の入力は28*28の一次元配列なのに、二次元配列のデータが入力されてしまいpythonがブチギレたということです。(ただし、チャネル数の次元は除く)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チャネル数を除く次元が1次元でないと、線形層は入力を受け付けません。だからこそ、フラット化が必要なわけですね。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、入力のサイズが合っていないのも、エラーの原因になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x784 and 756x20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#flat_imageは28*28の一次元配列なのに、入力は28*27→エラー\u001b[39;00m\n\u001b[0;32m      2\u001b[0m err_layer1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(in_features\u001b[39m=\u001b[39m\u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m27\u001b[39m, out_features\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m hidden1 \u001b[39m=\u001b[39m err_layer1(flat_image)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(hidden1\u001b[39m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\venv\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x784 and 756x20)"
     ]
    }
   ],
   "source": [
    "#flat_imageは28*28の一次元配列なのに、入力は28*27→エラー\n",
    "err_layer1 = nn.Linear(in_features=28*27, out_features=20)\n",
    "hidden1 = err_layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU層...活性化関数の一つReLU関数をもちいて、入力データを変化させる層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1740, 0.5786, 0.0000, 0.1441, 0.0000, 0.0209, 0.0000, 0.0000, 0.6372,\n",
      "         0.4300, 0.1162, 0.1729, 0.0000, 1.0431, 0.0000, 0.3307, 0.0000, 0.0141,\n",
      "         0.1596, 0.0432]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(1,28,28)\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "hidden1 = layer1(flat_image)\n",
    "out_relu=nn.ReLU()(hidden1)\n",
    "print(out_relu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このReLU関数は以下のように示されます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_model(x):\n",
    "    if x>0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、LinearとReLUとFlattenだけ使うと、モデルは以下のようにも定義し直すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1=nn.Linear(28*28,512)\n",
    "        self.Re1=nn.ReLU()\n",
    "        self.fc2=nn.Linear(512,512)\n",
    "        self.Re2=nn.ReLU()\n",
    "        self.fc3=nn.Linear(512,10)\n",
    "    def forward(self, x):\n",
    "        #層を一つ一つ指定して処理を書く\n",
    "        x = self.flatten(x)\n",
    "        x=self.fc1(x)\n",
    "        x=self.Re1(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.Re2(x)\n",
    "        logits=self.fc3(x)\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかし、これを見るとforwardのところが少し冗長（無駄に長い）ように感じます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このforwardの処理は「順伝搬」とよばれます。順伝搬は、入力データをある層に入れてその層の出力を別の層に入力するという一連の処理のことを指します。この順伝搬の処理を書くにあたり、どの順番で層を通るのかを指定する必要があるので、このような冗長なコードとなってしまうのです。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そこで、いくつかの層をまとめて、一つの構造体を作ることで順伝搬の処理をより容易に書くことができます。それがnn.Sequentialです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0277,  0.1467,  0.0084, -0.0111,  0.0598, -0.0301,  0.1294,  0.0153,\n",
      "          0.0468,  0.0775]], grad_fn=<AddmmBackward0>)\n",
      "SequentialModel(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_seq): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        #ここで使う\n",
    "        self.linear_seq=nn.Sequential(\n",
    "        nn.Linear(28*28,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits=self.linear_seq(x)\n",
    "        return logits\n",
    "    \n",
    "input_data=torch.rand(1,28,28)\n",
    "seq=SequentialModel()\n",
    "logits=seq(input_data)\n",
    "print(logits)\n",
    "print(seq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように順伝搬のところがすっきりします。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SoftMax層...ソフトマックス関数を用いて、モデルの最終出力を0から1までの値に直す層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0277,  0.1467,  0.0084, -0.0111,  0.0598, -0.0301,  0.1294,  0.0153,\n",
      "          0.0468,  0.0775]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0932, 0.1109, 0.0966, 0.0947, 0.1017, 0.0929, 0.1090, 0.0972, 0.1004,\n",
      "         0.1035]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "print(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "補足，畳み込み層"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからはCNNで使う層について説明します。CNNを学習するのはまだですが覚えておいて損はしません。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層...データの特徴を抽出する層(?)。パラメータの削減にも繋がる便利な層。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この層が行う処理は、最初聞いただけでは「?」ですが、画像認識に限らず、色んな場面で使うので、理解していきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0707, -0.3690, -0.2722, -0.2176, -0.6717, -0.4614],\n",
      "         [-0.2187, -0.5794, -0.5742,  0.0082, -0.4647, -0.2522],\n",
      "         [-0.4068, -0.2224, -0.4991, -0.4461, -0.4735, -0.4634],\n",
      "         [-0.9353, -0.1874, -0.4183, -0.7560, -0.4998, -0.6876],\n",
      "         [-0.2851, -0.5675,  0.1137, -0.4073, -0.6404, -0.4579],\n",
      "         [-0.0427, -0.7599, -0.4247, -0.3312, -0.7007, -0.2728]],\n",
      "\n",
      "        [[ 0.0102,  0.0813,  0.0586,  0.1369,  0.2562,  0.2612],\n",
      "         [-0.0820,  0.1109,  0.0124, -0.0695,  0.2094,  0.0936],\n",
      "         [-0.0428, -0.0328, -0.0650, -0.1414,  0.0691, -0.1170],\n",
      "         [ 0.0359,  0.0802,  0.0599,  0.1983,  0.2090, -0.0931],\n",
      "         [ 0.1813,  0.1071,  0.0158,  0.2180,  0.2374,  0.0338],\n",
      "         [ 0.0835,  0.1605, -0.0829,  0.1908,  0.1380,  0.0526]],\n",
      "\n",
      "        [[-0.3936,  0.0351,  0.2058, -0.1227,  0.2203,  0.3411],\n",
      "         [ 0.1337, -0.1204, -0.2169,  0.0418, -0.2056,  0.0691],\n",
      "         [ 0.0579, -0.2827, -0.0233, -0.2716, -0.1213, -0.0650],\n",
      "         [-0.2874,  0.4265, -0.1352, -0.1314,  0.4950, -0.4967],\n",
      "         [-0.1762,  0.1918, -0.1550,  0.1108,  0.2457, -0.1986],\n",
      "         [ 0.2445, -0.4443,  0.3034, -0.0824, -0.1401,  0.1121]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([3, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "input_conv=torch.rand(1,8,8)\n",
    "#入力チャネル1、出力チャネル3、カーネルサイズ3*3の畳み込み層\n",
    "conv1=nn.Conv2d(1,3,3)\n",
    "hidden_conv=conv1(input_conv)\n",
    "print(hidden_conv)\n",
    "print(hidden_conv.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層の処理はコードを実行しただけではさっぱりです。分かるとすれば、入力のデータが[1,8,8]だったのが[3,6,6]に変化したくらいです。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、この畳み込み層の解説をしましょう。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層では、カーネルというものがPytorchによって複数用意されます。カーネルとはランダムな数値を持つ小さな行列のことです。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このカーネルと画像のある一部分とのアダマール積を求めて、その成分の合計を一つの行列の値とします（語彙力）。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まあ見てもらった方が早いです<p><p><img src=\"https://camo.qiitausercontent.com/12545193254e3938b8914f22cdff6e238eab2d4b/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3232313834352f33636231326232312d383539612d393331312d326165362d3735363932383231313931302e676966\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のgifだと、カーネルが以下の行列で示されます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "|1 0 1|\n",
    "|0 1 0|\n",
    "|1 0 1|\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層では、このカーネルの数が、出力のチャネル数に対応します。上のコードを例にすると、チャネル数１のデータがカーネル数3の畳み込み層に入力されると、出力チャネル数が3となります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、出力のサイズが変化しているのもこの畳み込みによる影響と言えます。そのため、情報の量が減少してしまうので、その分チャネル数を増やすことで情報を補っているというわけです。(諸説あり) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この複数のカーネルというフィルターをかけて特徴を抽出するのが、畳み込み層の役割なんですね。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかし、いくら畳み込んだとしても学習データはチャネル数１にしないといけません。そこで、viewというtensor型のメソッドを紹介します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 6])\n",
      "torch.Size([1, 108])\n"
     ]
    }
   ],
   "source": [
    "input_conv=torch.rand(1,8,8)\n",
    "#入力チャネル1、出力チャネル3、カーネルサイズ3*3の畳み込み層\n",
    "conv1=nn.Conv2d(1,3,3)\n",
    "hidden_conv=conv1(input_conv)\n",
    "print(hidden_conv.size())\n",
    "#チャネル数3の6*6のデータなので、チャネル数1の要素3*6*6のデータに直す\n",
    "view_hidden=hidden_conv.view(-1,3*6*6)\n",
    "print(view_hidden.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これにより線形層での学習ができるようになります．今回は以上です．お疲れ様でした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15ceeb7393f0aff2609f088f7fc6d439204a45655252d34f7ade3b35005ea835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
